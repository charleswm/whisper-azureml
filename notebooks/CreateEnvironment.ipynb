{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/openai/whisper.git"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting git+https://github.com/openai/whisper.git\n  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-arhe51sz\n  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-arhe51sz\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from whisper==1.0) (1.21.6)\nRequirement already satisfied: torch in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from whisper==1.0) (1.12.0)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from whisper==1.0) (4.64.0)\nCollecting more-itertools\n  Using cached more_itertools-9.0.0-py3-none-any.whl (52 kB)\nCollecting transformers>=4.19.0\n  Using cached transformers-4.24.0-py3-none-any.whl (5.5 MB)\nCollecting ffmpeg-python==0.2.0\n  Using cached ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\nRequirement already satisfied: typing-extensions in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from torch->whisper==1.0) (4.3.0)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\nRequirement already satisfied: regex!=2019.12.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers>=4.19.0->whisper==1.0) (2022.7.25)\nCollecting huggingface-hub<1.0,>=0.10.0\n  Using cached huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\nRequirement already satisfied: requests in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers>=4.19.0->whisper==1.0) (2.28.1)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from transformers>=4.19.0->whisper==1.0) (3.7.1)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n\u001b[K     |████████████████████████████████| 7.6 MB 8.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: future in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.18.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.26.9)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.6.15)\nRequirement already satisfied: charset-normalizer<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.3)\nBuilding wheels for collected packages: whisper\n  Building wheel for whisper (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n\u001b[?25h  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175231 sha256=c3e260f575048bd8d02fa4bfd1a71cd5091f12d1b2070979075d79345fd55b72\n  Stored in directory: /tmp/pip-ephem-wheel-cache-_8lxg29n/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\nSuccessfully built whisper\n\u001b[31mERROR: azureml-automl-dnn-nlp 1.44.0 has requirement transformers<=4.5.1,>=4.1.0, but you'll have transformers 4.24.0 which is incompatible.\u001b[0m\nInstalling collected packages: more-itertools, huggingface-hub, tokenizers, transformers, ffmpeg-python, whisper\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.8.1\n    Uninstalling huggingface-hub-0.8.1:\n      Successfully uninstalled huggingface-hub-0.8.1\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.10.3\n    Uninstalling tokenizers-0.10.3:\n      Successfully uninstalled tokenizers-0.10.3\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.5.1\n    Uninstalling transformers-4.5.1:\n      Successfully uninstalled transformers-4.5.1\nSuccessfully installed ffmpeg-python-0.2.0 huggingface-hub-0.11.0 more-itertools-9.0.0 tokenizers-0.13.2 transformers-4.24.0 whisper-1.0\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\r\n",
        "\r\n",
        "whisper.load_model(\"base.en\", download_root=\"./model\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|███████████████████████████████████████| 139M/139M [00:03<00:00, 40.5MiB/s]\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "Whisper(\n  (encoder): AudioEncoder(\n    (conv1): Conv1d(80, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n    (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n    (blocks): ModuleList(\n      (0): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate=none)\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (1): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate=none)\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (2): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate=none)\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (3): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate=none)\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (4): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate=none)\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (5): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate=none)\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (ln_post): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n  )\n  (decoder): TextDecoder(\n    (token_embedding): Embedding(51864, 512)\n    (blocks): ModuleList(\n      (0): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (cross_attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (cross_attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate=none)\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (1): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (cross_attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (cross_attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate=none)\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (2): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (cross_attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (cross_attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate=none)\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (3): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (cross_attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (cross_attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate=none)\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (4): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (cross_attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (cross_attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate=none)\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (5): ResidualAttentionBlock(\n        (attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (cross_attn): MultiHeadAttention(\n          (query): Linear(in_features=512, out_features=512, bias=True)\n          (key): Linear(in_features=512, out_features=512, bias=False)\n          (value): Linear(in_features=512, out_features=512, bias=True)\n          (out): Linear(in_features=512, out_features=512, bias=True)\n        )\n        (cross_attn_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): Sequential(\n          (0): Linear(in_features=512, out_features=2048, bias=True)\n          (1): GELU(approximate=none)\n          (2): Linear(in_features=2048, out_features=512, bias=True)\n        )\n        (mlp_ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (ln): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1668801873783
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Load Model '''\r\n",
        "\r\n",
        "#import required libraries for workspace\r\n",
        "from azure.ai.ml import MLClient\r\n",
        "from azure.identity import DefaultAzureCredential\r\n",
        "\r\n",
        "#import required libraries for environments examples\r\n",
        "from azure.ai.ml.entities import Environment, BuildContext\r\n",
        "from azure.ai.ml.entities import Model\r\n",
        "from azure.ai.ml.constants import ModelType\r\n",
        "\r\n",
        "\r\n",
        "#Enter details of your AzureML workspace\r\n",
        "subscription_id = 'subscription id'\r\n",
        "resource_group = 'resource group'\r\n",
        "workspace = 'workspace'\r\n",
        "\r\n",
        "#connect to the workspace\r\n",
        "#ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)\r\n",
        "ml_client = MLClient.from_config(DefaultAzureCredential())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /mnt/batch/tasks/shared/LS_root/mounts/clusters/jacwang1/code/Users/jacwang/config.json\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1668807240945
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "file_model = Model(\r\n",
        "    path=\"model/base.en.pt\",\r\n",
        "    type=\"custom_model\",\r\n",
        "    name=\"whisper-base\",\r\n",
        "    description=\"Model created from local file.\"\r\n",
        ")\r\n",
        "ml_client.models.create_or_update(file_model)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "Model({'job_name': None, 'is_anonymous': False, 'auto_increment_version': False, 'name': 'whisper-base', 'description': 'Model created from local file.', 'tags': {}, 'properties': {}, 'id': '/subscriptions/7fd76d0f-84f2-498b-a997-e0d059af5ce1/resourceGroups/wu2modtimerg/providers/Microsoft.MachineLearningServices/workspaces/wu1modtimesml2/models/whisper-base/versions/2', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/jacwang1/code/Users/jacwang/whisper-azureml/notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd065c8fc10>, 'serialize': <msrest.serialization.Serializer object at 0x7fd065ce3730>, 'version': '2', 'latest_version': None, 'path': 'azureml://subscriptions/7fd76d0f-84f2-498b-a997-e0d059af5ce1/resourceGroups/wu2modtimerg/workspaces/wu1modtimesml2/datastores/workspaceblobstore/paths/LocalUpload/e29f3bdba7a2b8245647b5271b95e5d7/base.en.pt', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1668807251798
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_docker_context = Environment(\r\n",
        "    build=BuildContext(path=\"../environment\"),\r\n",
        "    name=\"whisper-base-env\",\r\n",
        "    description=\"Environment created from a Docker context.\",\r\n",
        ")\r\n",
        "ml_client.environments.create_or_update(env_docker_context)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\rUploading environment (0.0 MBs):   0%|          | 0/389 [00:00<?, ?it/s]\rUploading environment (0.0 MBs): 100%|██████████| 389/389 [00:00<00:00, 10280.48it/s]\n\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "Environment({'is_anonymous': False, 'auto_increment_version': False, 'name': 'whisper-base-env', 'description': 'Environment created from a Docker context.', 'tags': {}, 'properties': {}, 'id': '/subscriptions/7fd76d0f-84f2-498b-a997-e0d059af5ce1/resourceGroups/wu2modtimerg/providers/Microsoft.MachineLearningServices/workspaces/wu1modtimesml2/environments/whisper-base-env/versions/2', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/jacwang1/code/Users/jacwang/whisper-azureml/notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd06617eeb0>, 'serialize': <msrest.serialization.Serializer object at 0x7fd065c82f10>, 'version': '2', 'latest_version': None, 'conda_file': None, 'image': None, 'build': <azure.ai.ml.entities._assets.environment.BuildContext object at 0x7fd065c82310>, 'inference_config': None, 'os_type': 'Linux', 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1668807405902
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}